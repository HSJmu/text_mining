{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kobert_test.ipynb와 다른점\n",
    "- softmax를 사용하여 기사 제목 및 내용별 긍부정 결과 뿐만 아닌 확률값 도출 가능\n",
    "- 배치사이즈를 주어서 배치별로 모델 적용을 시켜 훨씬 빠른 결과값 도출 가능"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from kobert import get_pytorch_kobert_model\n",
    "from kobert import get_tokenizer\n",
    "\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모델 불러오기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터셋 클래스 정의 \n",
    "- 모델 학습할 때 사용한 데이터셋 클래스 정의, 입력 데이터와 레이블을 적절한 형태로 변환하여 제공하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        self.sentences = [transform([str(i[sent_idx])]) for i in dataset]\n",
    "        self.labels = [i[label_idx] for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 하이퍼파라미터 및 device 지정\n",
    "- 모델 학습 시 사용한 하이퍼파라미터 및 장치 설정을 동일하게 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "seed = 0\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 클래스 정의와 인스턴스화\n",
    "- 학습할 때 사용한 모델 클래스 정의 및 해당 클래스를 사용한 모델 객체 인스턴스화를 통해 모델 구조와 설정 재현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBERT 모델\n",
    "class BERTClassifier(nn.Module):\n",
    "  def __init__(self, bert, hidden_size=768, num_classes=2, dr_rate=None, params=None):\n",
    "    super(BERTClassifier, self).__init__()\n",
    "    self.bert = bert\n",
    "    self.dr_rate = dr_rate\n",
    "\n",
    "    self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "    if dr_rate:\n",
    "      self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "  def gen_attention_mask(self, token_ids, valid_length):\n",
    "    attention_mask = torch.zeros_like(token_ids)\n",
    "    for i, v in enumerate(valid_length):\n",
    "      attention_mask[i][:v] = 1\n",
    "    return attention_mask.float()\n",
    "\n",
    "  def forward(self, token_ids, valid_length, segment_ids):\n",
    "    attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "    _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "    if self.dr_rate:\n",
    "        out = self.dropout(pooler)\n",
    "    else:\n",
    "        out = pooler\n",
    "    return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/hnu/바탕화면/Lab/.cache/kobert_v1.zip\n",
      "using cached model. /home/hnu/바탕화면/Lab/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/hnu/바탕화면/Lab/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "# 모델 불러오기\n",
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)  # 모델 클래스를 정의하고 인스턴스화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 저장된 모델 가중치 로드\n",
    "- 학습된 모델 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델의 가중치 로드\n",
    "model.load_state_dict(torch.load(\"naverShoppingReview_state_dict.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 적용 예시\n",
    "- 클래스는 총 2개(부정, 긍정)이며 부정, 긍정에 대한 소프트맥스 값 비교\n",
    "- 각 클래스에 대한 확률값을 비교해 더 높은 값의 클래스를 예측해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수 생성\n",
    "def predict_proba(predict_sentence):\n",
    "    predict_sentence = predict_sentence.reshape(-1, 1)\n",
    "    zeros = np.zeros((len(predict_sentence), 1), dtype=np.int32)\n",
    "\n",
    "    dataset_another = np.concatenate([predict_sentence, zeros], axis=1)\n",
    "    test_dataset = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(predict_sentence), num_workers=5, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for token_ids, valid_length, segment_ids, label in test_loader:\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "            valid_length = valid_length.to(device)\n",
    "            label = label.long().to(device)\n",
    "\n",
    "            out = model(token_ids, valid_length, segment_ids)\n",
    "            scores = torch.softmax(out, dim=1)\n",
    "            all_scores.extend(scores.detach().cpu().numpy())\n",
    "    \n",
    "    total_result = list(map(lambda x: '부정' if x[0] > x[1] else '긍정', all_scores))\n",
    "    positive_score = list(map(lambda x: x[1], all_scores)) # ['부정', '긍정', '부정']\n",
    "    return total_result, positive_score  # 긍부정 판단반환값, 긍정 클래스에 대한 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(col_name):\n",
    "    # 전체 기사 concat\n",
    "    files = os.listdir(f\"{col_name}2/\")\n",
    "    dfs = []\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        file_path = os.path.join(f\"{col_name}2\", file)\n",
    "        try : \n",
    "            df = pd.read_csv(file_path)\n",
    "        except pd.errors.EmptyDataError :\n",
    "            continue\n",
    "        dfs.append(df)\n",
    "\n",
    "    dfs = pd.concat(dfs, ignore_index=True)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_batch(dfs, batch_size):\n",
    "    title_content_values = dfs[['기사제목', '기사내용']].values\n",
    "    title_content_values_len = len(title_content_values)\n",
    "    \n",
    "    test_batch_size = int(np.floor(title_content_values_len / batch_size))\n",
    "    \n",
    "    sentence_split = np.array_split(title_content_values, test_batch_size)\n",
    "    sentence_split_len = len(sentence_split)\n",
    "    return sentence_split, sentence_split_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_result(col_name):\n",
    "    ## 데이터 합치기\n",
    "    dfs = concat_df(col_name)\n",
    "\n",
    "    ## test batch 생성\n",
    "    sentence_split, sentence_split_len = get_test_batch(dfs, 1024)\n",
    "\n",
    "    ## 결과 추출\n",
    "    result_dict = {\n",
    "        '기사제목_감정분석': [],\n",
    "        '기사제목_긍정스코어': [],\n",
    "        '기사내용_감정분석': [],\n",
    "        '기사내용_긍정스코어': [],\n",
    "    }\n",
    "\n",
    "    with tqdm(total=len(sentence_split)) as pbar:\n",
    "        for idx, batch_sample in enumerate(sentence_split):\n",
    "            batch_title_sample = batch_sample[:, 0].copy()\n",
    "            batch_content_sample = batch_sample[:, 1].copy()\n",
    "\n",
    "            text_score1, float_score1 = predict_proba(batch_title_sample)\n",
    "            result_dict['기사제목_감정분석'] += text_score1\n",
    "            result_dict['기사제목_긍정스코어'] += float_score1\n",
    "\n",
    "            text_score2, float_score2 = predict_proba(batch_content_sample)\n",
    "            result_dict['기사내용_감정분석'] += text_score2\n",
    "            result_dict['기사내용_긍정스코어'] += float_score2\n",
    "            pbar.update(1)\n",
    "\n",
    "    result = pd.DataFrame(result_dict)\n",
    "    dfs = pd.concat([dfs, result], axis = 1)\n",
    "\n",
    "    file = dfs[['기사제목','기사제목_감정분석','기사제목_긍정스코어','기사내용', '기사내용_감정분석','기사내용_긍정스코어','언론사', '년도', '월', 'url']]\n",
    "    file.to_csv(f\"sentiment_analysis_{col_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7305 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7305/7305 [00:20<00:00, 356.01it/s]\n",
      "100%|██████████| 780/780 [28:32<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "get_total_result('항만')\n",
    "# get_total_result('무역')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('sentiment_analysis_무역.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
